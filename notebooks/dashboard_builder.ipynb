{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2baf465a",
   "metadata": {},
   "source": [
    "# Dashboard final — visualisations avancées \n",
    "\n",
    "Ce notebook lit les artefacts produits par l'analyse (dans `outputs/analysis_results`) et génère :\n",
    "\n",
    "- Projection UMAP\n",
    "- Barplot de couverture par thème\n",
    "- Heatmap lexical vs sémantique\n",
    "- Distribution de similarité par thème\n",
    "- Wordcloud des entités Forbes\n",
    "- Tableaux filtrables\n",
    "- Interprétations automatiques\n",
    "\n",
    "Aucune écriture n'est faite par défaut; exécute cellule par cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62820fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & chemins\n",
    "import os, json\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from IPython.display import display, HTML\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "\n",
    "RES = os.path.join('./outputs/analysis_results')\n",
    "ARTIFACTS = {}\n",
    "if os.path.exists(RES):\n",
    "    ARTIFACTS = {fn: os.path.join(RES,fn) for fn in os.listdir(RES)}\n",
    "print('Results folder:', RES)\n",
    "print('Found artifacts:', sorted(list(ARTIFACTS.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b5cf7",
   "metadata": {},
   "source": [
    "## Charger les fichiers produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if(fn):\n",
    "    p = os.path.join(RES, fn)\n",
    "    return pd.read_csv(p) if os.path.exists(p) else None\n",
    "\n",
    "coords = load_if('umap_coords_with_meta.csv')\n",
    "cov = load_if('coverage_combined_forbes.csv')\n",
    "sim = load_if('semantic_similarity_forbes.csv')\n",
    "lex = load_if('lexical_coverage_forbes.csv')\n",
    "sent = load_if('document_sentiment.csv')\n",
    "aspect = load_if('aspect_sentiment_forbes.csv')\n",
    "fr = load_if('framing_forbes.csv')\n",
    "ents = load_if('forbes_entities.csv')\n",
    "pairs = load_if('oms_to_forbes_pairs.csv')\n",
    "art = None\n",
    "if os.path.exists(os.path.join(OUT_DIR,'all_articles_processed.csv')):\n",
    "    art = pd.read_csv(os.path.join(OUT_DIR,'all_articles_processed.csv'))\n",
    "elif os.path.exists(os.path.join(OUT_DIR,'all_articles_processed.csv')):\n",
    "    art = pd.read_csv(os.path.join(OUT_DIR,'all_articles_processed.csv'))\n",
    "\n",
    "print('Loaded: coords', coords is not None, 'cov', cov is not None, 'sim', sim is not None, 'lex', lex is not None)\n",
    "print('Loaded: sent', sent is not None, 'aspect', aspect is not None, 'fr', fr is not None, 'ents', ents is not None, 'pairs', pairs is not None)\n",
    "print('Articles DF loaded:', art is not None if art is not None else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c220a",
   "metadata": {},
   "source": [
    "## Projection UMAP — Visualisation des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coords is None:\n",
    "    print('UMAP coordinates not found. Skipping UMAP plot.')\n",
    "else:\n",
    "    hover_cols = []\n",
    "    for c in ['preview','title','source','date']:\n",
    "        if c in coords.columns:\n",
    "            hover_cols.append(c)\n",
    "    fig = px.scatter(coords, x='umap_x', y='umap_y', color='source' if 'source' in coords.columns else None,\n",
    "                     hover_data=hover_cols, height=700, title='Projection UMAP — Visualisation des articles')\n",
    "    fig.update_traces(marker=dict(size=6, opacity=0.8))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee0663",
   "metadata": {},
   "source": [
    "## Couverture des thèmes OMS par Forbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cov is None:\n",
    "    print('Coverage file missing — skipping coverage bar.')\n",
    "else:\n",
    "    topic_cols = [c for c in cov.columns if c.startswith('covered_topic_')]\n",
    "    cover_counts = cov[topic_cols].sum().reset_index()\n",
    "    cover_counts.columns = ['metric','count']\n",
    "    cover_counts['topic'] = cover_counts['metric'].str.replace('covered_topic_','').astype(int)\n",
    "    fig = px.bar(cover_counts, x='topic', y='count', title=\"Nombre d’articles Forbes couvrant chaque thème de l’OMS\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6566d4",
   "metadata": {},
   "source": [
    "## Heatmap — Moyenne lexicale et sémantique par thématique OMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if lex is None and sim is None:\n",
    "    print('Lexical and semantic files missing — skipping heatmap.')\n",
    "else:\n",
    "    rows = []\n",
    "    topic_ids = set()\n",
    "    if lex is not None:\n",
    "        topic_ids |= {int(c.replace('lex_topic_','')) for c in lex.columns if c.startswith('lex_topic_')}\n",
    "    if sim is not None:\n",
    "        topic_ids |= {int(c.replace('sim_topic_','')) for c in sim.columns if c.startswith('sim_topic_')}\n",
    "    topic_ids = sorted(topic_ids)\n",
    "    for t in topic_ids:\n",
    "        mean_lex = lex[f'lex_topic_{t}'].mean() if (lex is not None and f'lex_topic_{t}' in lex.columns) else np.nan\n",
    "        mean_sim = sim[f'sim_topic_{t}'].mean() if (sim is not None and f'sim_topic_{t}' in sim.columns) else np.nan\n",
    "        rows.append({'topic':t,'mean_lex':mean_lex,'mean_sim':mean_sim})\n",
    "    df_metrics = pd.DataFrame(rows).set_index('topic')\n",
    "    plt.figure(figsize=(6, max(4, len(df_metrics)*0.5)))\n",
    "    sns.heatmap(df_metrics.fillna(0), annot=True, fmt='.2f', cmap='viridis')\n",
    "    plt.title('Moyenne lexicale et sémantique par thématique OMS')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1bdc1",
   "metadata": {},
   "source": [
    "## Distribution de la similarité sémantique par thématique OMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9531d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sim is None:\n",
    "    print('Semantic similarity file missing — skipping similarity distributions.')\n",
    "else:\n",
    "    sim_cols = [c for c in sim.columns if c.startswith('sim_topic_')]\n",
    "    sim_long = sim.melt(id_vars=['global_index'], value_vars=sim_cols, var_name='topic', value_name='sim')\n",
    "    sim_long['topic'] = sim_long['topic'].str.replace('sim_topic_','').astype(int)\n",
    "    fig = px.box(sim_long, x='topic', y='sim', points='outliers', title='Distribution de la similarité sémantique par thématique OMS')\n",
    "    fig.update_layout(xaxis_title='ID thématique', yaxis_title='Similarité cosinus')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d193f56",
   "metadata": {},
   "source": [
    "## Wordcloud / Top entités (Forbes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ents is None:\n",
    "    print('Entities file missing — skipping wordcloud.')\n",
    "else:\n",
    "    try:\n",
    "        from wordcloud import WordCloud\n",
    "        have_wordcloud = True\n",
    "    except Exception:\n",
    "        have_wordcloud = False\n",
    "        print('WordCloud lib not installé — affichage du top entities à la place.')\n",
    "\n",
    "    ent_counts = ents.groupby(['entity','label']).size().reset_index(name='count').sort_values('count', ascending=False)\n",
    "    display(ent_counts.head(30))\n",
    "\n",
    "    if have_wordcloud:\n",
    "        freq = {row['entity']: int(row['count']) for _, row in ent_counts.head(500).iterrows()}\n",
    "        wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title('Top entités (Forbes)')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596e58a",
   "metadata": {},
   "source": [
    "## Tableaux filtrables (Source / Mot-clé / Sentiment / Framing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff760452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "if art is None:\n",
    "    print('Articles CSV non trouvé — impossible d\\'afficher la table interactive.')\n",
    "else:\n",
    "    df_articles = art.copy()\n",
    "    if 'preview' not in df_articles.columns:\n",
    "        df_articles['preview'] = df_articles.get('title','').astype(str)\n",
    "    if sent is not None:\n",
    "        sd = sent[['global_index','label']].rename(columns={'global_index':'index','label':'sent_label'})\n",
    "        df_articles = df_articles.reset_index().rename(columns={'index':'index'}).merge(sd, left_on='index', right_on='index', how='left').set_index('index')\n",
    "    if fr is not None:\n",
    "        frs = fr[['global_index','framing']].rename(columns={'global_index':'index'})\n",
    "        df_articles = df_articles.reset_index().merge(frs, left_on='index', right_on='index', how='left').set_index('index')\n",
    "    display(df_articles[['source','title','preview']].head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b057cb",
   "metadata": {},
   "source": [
    "## Interprétations automatiques (brouillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretations = []\n",
    "if cov is not None:\n",
    "    topic_cols = [c for c in cov.columns if c.startswith('covered_topic_')]\n",
    "    cover_counts = cov[topic_cols].sum().rename(lambda x: int(x.replace('covered_topic_','')))\n",
    "    top_topics = cover_counts.sort_values(ascending=False).head(3)\n",
    "    interpretations.append(f\"Top thèmes couverts par Forbes : {', '.join([f'Theme {t} ({int(c)})' for t,c in top_topics.items()])}.\")\n",
    "else:\n",
    "    interpretations.append('Aucune donnée de couverture disponible.')\n",
    "\n",
    "if sent is not None:\n",
    "    s = sent['label'].value_counts()\n",
    "    total = s.sum()\n",
    "    pos = s.filter(like='POS').sum() if any(['POS' in str(x).upper() for x in s.index]) else s.get('POS',0) if 'POS' in s.index else 0\n",
    "    neg = s.filter(like='NEG').sum() if any(['NEG' in str(x).upper() for x in s.index]) else s.get('NEG',0) if 'NEG' in s.index else 0\n",
    "    interpretations.append(f\"Sentiment documents : POS ~{int(pos)}/{int(total)}, NEG ~{int(neg)}/{int(total)} (comptes bruts).\")\n",
    "else:\n",
    "    interpretations.append('Pas de fichier de sentiment disponible.')\n",
    "\n",
    "if fr is not None and not fr.empty:\n",
    "    framing_counts = fr['framing'].value_counts()\n",
    "    dominant = framing_counts.idxmax()\n",
    "    interpretations.append(f\"Angle dominant parmi les articles couverts : {dominant} (counts: {framing_counts.to_dict()}).\")\n",
    "else:\n",
    "    interpretations.append('Pas de fichier de framing disponible.')\n",
    "\n",
    "if ents is not None:\n",
    "    top_ent = ents.groupby('entity').size().sort_values(ascending=False).head(10)\n",
    "    interpretations.append('Top entités mentionnées : ' + ', '.join([f\"{e} ({c})\" for e,c in top_ent.items()]) + '.')\n",
    "else:\n",
    "    interpretations.append('Pas de fichier d\\'entités disponible.')\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "display(HTML('<h3>Interprétations automatiques (brouillon)</h3>'))\n",
    "for p in interpretations:\n",
    "    display(HTML(f\"<p>{p}</p>\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
